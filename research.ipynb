{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1V5ZrltKHymBPLTJM-w1UTp-VrrTaomZH",
      "authorship_tag": "ABX9TyMKHYG4urVXK/fjIDUQGsrZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UmbertoB/neural-networks-research/blob/main/research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zb1gGMb9tr1m",
        "outputId": "74cf2b38-ab51-4d5c-95ca-d98b8a342ebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 120000)            0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               15360128  \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,360,257\n",
            "Trainable params: 15,360,257\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Modelo Compilado...\n",
            "drive/MyDrive/DATASET\n",
            "Found 2100 images belonging to 2 classes.\n",
            "Found 600 images belonging to 2 classes.\n",
            "Found 300 images belonging to 2 classes.\n",
            "Iniciando treino do Modelo...\n",
            "Epoch 1/30\n",
            "263/263 [==============================] - ETA: 0s - loss: 13.8843 - acc: 0.6786\n",
            "Epoch 1: val_acc improved from -inf to 0.73833, saving model to model_one.hdf5\n",
            "263/263 [==============================] - 42s 158ms/step - loss: 13.8843 - acc: 0.6786 - val_loss: 1.0341 - val_acc: 0.7383 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "263/263 [==============================] - ETA: 0s - loss: 0.6051 - acc: 0.7243\n",
            "Epoch 2: val_acc improved from 0.73833 to 0.76333, saving model to model_one.hdf5\n",
            "263/263 [==============================] - 39s 150ms/step - loss: 0.6051 - acc: 0.7243 - val_loss: 0.5591 - val_acc: 0.7633 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "263/263 [==============================] - ETA: 0s - loss: 0.5323 - acc: 0.7529\n",
            "Epoch 3: val_acc did not improve from 0.76333\n",
            "263/263 [==============================] - 40s 153ms/step - loss: 0.5323 - acc: 0.7529 - val_loss: 0.5359 - val_acc: 0.7600 - lr: 0.0010\n",
            "Epoch 4/30\n",
            " 83/263 [========>.....................] - ETA: 21s - loss: 0.5384 - acc: 0.7229"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import InceptionResNetV2, VGG16\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from keras.regularizers import l2\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, ZeroPadding2D, Flatten, Dense, Activation, Dropout, \\\n",
        "    GlobalAveragePooling2D\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.layers import BatchNormalization\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "import numpy as np\n",
        "\n",
        "def compile_model(layers, alpha):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    for layer in layers:\n",
        "        model.add(layer)\n",
        "\n",
        "    opt = Adam(learning_rate=alpha)\n",
        "\n",
        "    model.build()\n",
        "    model.summary()\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=opt,\n",
        "                  metrics=['acc'])\n",
        "\n",
        "    print(\"Modelo Compilado...\")\n",
        "    return model\n",
        "\n",
        "\n",
        "def data_augment(dataset_path, batch_size, input_shape):\n",
        "    image_gen = ImageDataGenerator(rotation_range=40, rescale=1 / 255, horizontal_flip=True, vertical_flip=True)\n",
        "\n",
        "    print(dataset_path)\n",
        "    train_images = image_gen.flow_from_directory(dataset_path + '/train', target_size=input_shape[:2],\n",
        "                                                 batch_size=batch_size, class_mode='binary')\n",
        "    validation_images = image_gen.flow_from_directory(dataset_path + '/validation',\n",
        "                                                      target_size=input_shape[:2], batch_size=batch_size,\n",
        "                                                      class_mode='binary')\n",
        "    test_images = image_gen.flow_from_directory(dataset_path + '/test', target_size=input_shape[:2],\n",
        "                                                batch_size=batch_size, class_mode='binary')\n",
        "\n",
        "    return train_images, validation_images, test_images\n",
        "\n",
        "\n",
        "def create_callbacks(alpha):\n",
        "    filepath = \"model_one.hdf5\"\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "    lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.1, min_delta=alpha, patience=5, verbose=1)\n",
        "    erl_stopping = tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss', verbose=1)\n",
        "\n",
        "    callbacks = [checkpoint, lr_reduce, erl_stopping]\n",
        "    return callbacks\n",
        "\n",
        "\n",
        "def generate_model(dataset_path, input_shape, batch_size, alpha, epoch, layers):\n",
        "    model = compile_model(layers, alpha)\n",
        "    callbacks = create_callbacks(alpha)\n",
        "    train_images, validation_images, test_images = data_augment(dataset_path, batch_size, input_shape)\n",
        "\n",
        "    print(\"Iniciando treino do Modelo...\")\n",
        "    history = model.fit(\n",
        "        train_images,\n",
        "        validation_data=validation_images,\n",
        "        callbacks=callbacks,\n",
        "        epochs=epoch)\n",
        "\n",
        "    model.evaluate(test_images)\n",
        "\n",
        "    return history, model\n",
        "\n",
        "\n",
        "bs = 8\n",
        "alp = 1e-3\n",
        "eph = 30\n",
        "i_shape = (200, 200, 3)\n",
        "lyrs = [Flatten(input_shape=i_shape),\n",
        "        Dense(128),\n",
        "        Dense(1, activation='sigmoid')]\n",
        "\n",
        "generate_model('drive/MyDrive/DATASET', i_shape, bs, alp, eph, lyrs)\n"
      ]
    }
  ]
}